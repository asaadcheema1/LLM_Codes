{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 141,
      "id": "f015f708",
      "metadata": {
        "height": 30,
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f015f708",
        "outputId": "15cdb1f2-19a5-4437-aa51-bbd14378878b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting docarray\n",
            "  Downloading docarray-0.40.0-py3-none-any.whl.metadata (36 kB)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from docarray) (1.26.4)\n",
            "Requirement already satisfied: orjson>=3.8.2 in /usr/local/lib/python3.10/dist-packages (from docarray) (3.10.11)\n",
            "Requirement already satisfied: pydantic>=1.10.8 in /usr/local/lib/python3.10/dist-packages (from docarray) (2.9.2)\n",
            "Requirement already satisfied: rich>=13.1.0 in /usr/local/lib/python3.10/dist-packages (from docarray) (13.9.4)\n",
            "Collecting types-requests>=2.28.11.6 (from docarray)\n",
            "  Downloading types_requests-2.32.0.20241016-py3-none-any.whl.metadata (1.9 kB)\n",
            "Requirement already satisfied: typing-inspect>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from docarray) (0.9.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.10.8->docarray) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.10.8->docarray) (2.23.4)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.10.8->docarray) (4.12.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=13.1.0->docarray) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=13.1.0->docarray) (2.18.0)\n",
            "Requirement already satisfied: urllib3>=2 in /usr/local/lib/python3.10/dist-packages (from types-requests>=2.28.11.6->docarray) (2.2.3)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect>=0.8.0->docarray) (1.0.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=13.1.0->docarray) (0.1.2)\n",
            "Downloading docarray-0.40.0-py3-none-any.whl (270 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m270.2/270.2 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading types_requests-2.32.0.20241016-py3-none-any.whl (15 kB)\n",
            "Installing collected packages: types-requests, docarray\n",
            "Successfully installed docarray-0.40.0 types-requests-2.32.0.20241016\n"
          ]
        }
      ],
      "source": [
        "# ! pip install langchain\n",
        "# ! pip install -U langchain-community\n",
        "# ! pip install pypdf\n",
        "# ! pip install chromadb\n",
        "# ! pip install tiktoken\n",
        "# ! pip install docarray"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "id": "f26c2a2a-f7a7-4580-ab73-178bab918dd7",
      "metadata": {
        "height": 166,
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f26c2a2a-f7a7-4580-ab73-178bab918dd7",
        "outputId": "55465389-d09d-47d4-de80-a3a48bcb1153"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "API key loaded successfully\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import openai\n",
        "os.environ['OPENAI_API_KEY']= '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'\n",
        "# Retrieve the API key from environment variables\n",
        "openai.api_key = os.getenv('OPENAI_API_KEY')\n",
        "# Now you can use the OpenAI API functions\n",
        "print(\"API key loaded successfully\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "id": "38ef5d48",
      "metadata": {
        "height": 64,
        "tags": [],
        "id": "38ef5d48"
      },
      "outputs": [],
      "source": [
        "from langchain.document_loaders import PyPDFLoader\n",
        "loader = PyPDFLoader(\"/content/CV_2024_v03.pdf\")\n",
        "pages = loader.load()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "id": "fd28c723-3625-4219-b0f8-8d5b761ae79e",
      "metadata": {
        "height": 30,
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fd28c723-3625-4219-b0f8-8d5b761ae79e",
        "outputId": "f69533ab-3471-4702-b4be-9191e17ad34d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ],
      "source": [
        "len(pages)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "id": "26ff4112",
      "metadata": {
        "height": 30,
        "tags": [],
        "id": "26ff4112"
      },
      "outputs": [],
      "source": [
        "page = pages[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "id": "5c94e3b5",
      "metadata": {
        "height": 30,
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5c94e3b5",
        "outputId": "85f61f2f-e8a6-4b28-f4a8-6fb46f1578d2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Muhammad Asaad Cheema\n",
            "Data Scientist/Software Developer\n",
            "Mobile: +47-46504338 Email: asaad.cheema@ntnu.no\n",
            "LinkedIn: Muhammad Asaad Cheema Country: Norway\n",
            "Introduction\n",
            "As a highly skilled and experienced Data Scientist and Analyst with research roles at prestigious institutions such as\n",
            "Imperial College London and the Norwegian University of Science and Technology, I bring profound expertise in\n",
            "Artificial Intelligence. My technical proficiency spans various programming languages, machine learning f\n"
          ]
        }
      ],
      "source": [
        "print(page.page_content[0:500])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "id": "605d0932",
      "metadata": {
        "height": 30,
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "605d0932",
        "outputId": "84759474-74b8-4ff1-cbc2-fbcbc5d6a4db"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'source': '/content/CV_2024_v03.pdf', 'page': 0}"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ],
      "source": [
        "page.metadata"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ead28868",
      "metadata": {
        "id": "ead28868"
      },
      "source": [
        "## YouTube"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "id": "4c5f360f",
      "metadata": {
        "height": 64,
        "tags": [],
        "id": "4c5f360f"
      },
      "outputs": [],
      "source": [
        "from langchain.document_loaders.generic import GenericLoader\n",
        "from langchain.document_loaders.parsers import OpenAIWhisperParser\n",
        "from langchain.document_loaders.blob_loaders.youtube_audio import YoutubeAudioLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "4835edd9",
      "metadata": {
        "height": 47,
        "tags": [],
        "id": "4835edd9"
      },
      "outputs": [],
      "source": [
        "# ! pip install yt_dlp\n",
        "# ! pip install pydub"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "adaa8f7a-bd04-4bbd-96a9-8c2088426885",
      "metadata": {
        "id": "adaa8f7a-bd04-4bbd-96a9-8c2088426885"
      },
      "source": [
        "**Note**: This can take several minutes to complete."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "id": "197f0936",
      "metadata": {
        "height": 132,
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "197f0936",
        "outputId": "757f4f49-7e37-49d5-a2ba-2ecf8dfd27f6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[youtube] Extracting URL: https://www.youtube.com/watch?v=9lS6MvTtrd8\n",
            "[youtube] 9lS6MvTtrd8: Downloading webpage\n",
            "[youtube] 9lS6MvTtrd8: Downloading ios player API JSON\n",
            "[youtube] 9lS6MvTtrd8: Downloading mweb player API JSON\n",
            "[youtube] 9lS6MvTtrd8: Downloading m3u8 information\n",
            "[info] 9lS6MvTtrd8: Downloading 1 format(s): 140\n",
            "[download] docs/youtube//Guardiola focus on upcoming games rather than past ｜ Press Conference ｜ Man City vs. Notts Forest.m4a has already been downloaded\n",
            "[download] 100% of    5.54MiB\n",
            "[ExtractAudio] Not converting audio docs/youtube//Guardiola focus on upcoming games rather than past ｜ Press Conference ｜ Man City vs. Notts Forest.m4a; file is already in target format m4a\n",
            "Transcribing part 1!\n"
          ]
        }
      ],
      "source": [
        "url=\"https://www.youtube.com/watch?v=9lS6MvTtrd8\"\n",
        "save_dir=\"docs/youtube/\"\n",
        "loader = GenericLoader(\n",
        "    YoutubeAudioLoader([url],save_dir),\n",
        "    OpenAIWhisperParser()\n",
        ")\n",
        "docs = loader.load()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "c2bf39c3",
      "metadata": {
        "height": 30,
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "c2bf39c3",
        "outputId": "51a4ad54-15a1-4916-93bf-b814edcb9271"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Hi Pep, you've spoken a lot and a lot of people have mentioned about the amount of players that have been injured or coming back to fitness. Do you accept that the longer this run goes on, that even when you get your players back, the team itself will never reach the levels that it reached the last four seasons? With all the squad this season, we'll be close to the level that we reached last season, yeah. So you still believe that you can get right to the levels that you were at with this squad?\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "docs[0].page_content[0:500]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6b54e6f9",
      "metadata": {
        "id": "6b54e6f9"
      },
      "source": [
        "## URLs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "id": "ede7f5d4",
      "metadata": {
        "height": 64,
        "tags": [],
        "id": "ede7f5d4"
      },
      "outputs": [],
      "source": [
        "from langchain.document_loaders import WebBaseLoader\n",
        "\n",
        "loader = WebBaseLoader(\"https://salvoros.folk.ntnu.no/SPIN/\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "id": "596c8f4e-6fd5-4230-9dfc-84e100e90d72",
      "metadata": {
        "height": 30,
        "tags": [],
        "id": "596c8f4e-6fd5-4230-9dfc-84e100e90d72"
      },
      "outputs": [],
      "source": [
        "docs_Spin = loader.load()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "id": "3039f8ed-ebc1-44e7-829a-9499dc5d1f03",
      "metadata": {
        "height": 30,
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3039f8ed-ebc1-44e7-829a-9499dc5d1f03",
        "outputId": "5982cae8-716d-450f-a3a8-c854bde20f0f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "SPIN@NTNU\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Welcome\n",
            "Who we are\n",
            "What we do\n",
            "Get in touch\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "The research group SPIN (Signal Processing for Industry N.0) focuses on research in statistical signal processing and machine learning applied to sensors data and related to the digitalization of the industrial sector, primarily within construction, energy, and ocean.\n",
            "SPIN is part of the Signal Processing Group at the\r\n",
            "\t\t\t\t\t\t\t\tDepartment of Electronic Systems,\r\n",
            "\t\t\t\t\t\t\t\t Faculty of Information Technology and Electrical \n"
          ]
        }
      ],
      "source": [
        "print(docs_Spin[0].page_content[:500])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Document Splitter"
      ],
      "metadata": {
        "id": "KLXDN_dgMrzf"
      },
      "id": "KLXDN_dgMrzf"
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "text_splitter = CharacterTextSplitter(\n",
        "    separator=\"\\n\",\n",
        "    chunk_size=150,\n",
        "    chunk_overlap=25,\n",
        "    length_function=len\n",
        ")"
      ],
      "metadata": {
        "id": "gOHTe7WOMwAm"
      },
      "id": "gOHTe7WOMwAm",
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "splits = text_splitter.split_documents(docs_Spin)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p2GptlyQM42N",
        "outputId": "8b8cf474-c743-4844-b291-858df44b34f9"
      },
      "id": "p2GptlyQM42N",
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain_text_splitters.base:Created a chunk of size 268, which is longer than the specified 150\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 180, which is longer than the specified 150\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 203, which is longer than the specified 150\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 155, which is longer than the specified 150\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.vectorstores import Chroma\n",
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "embedding = OpenAIEmbeddings()"
      ],
      "metadata": {
        "id": "HpLnOHcPNB9V"
      },
      "id": "HpLnOHcPNB9V",
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "persist_directory = 'docs/chroma/'"
      ],
      "metadata": {
        "id": "xktyAVa-QNdY"
      },
      "id": "xktyAVa-QNdY",
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf ./docs/chroma  # remove old database files if any"
      ],
      "metadata": {
        "id": "jSDhzAj2QOia"
      },
      "id": "jSDhzAj2QOia",
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vectordb = Chroma.from_documents(\n",
        "    documents=splits,\n",
        "    embedding=embedding,\n",
        "    persist_directory=persist_directory\n",
        ")"
      ],
      "metadata": {
        "id": "18LLZWSqQSMt"
      },
      "id": "18LLZWSqQSMt",
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Small Test\n",
        "question = \"Who is Salvo Rossi?\"\n",
        "docs = vectordb.similarity_search(question,k=3)\n",
        "len(docs)\n",
        "docs[0].page_content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "stJrWprLQxIN",
        "outputId": "b5c2669a-1de0-4b7b-9304-605dff4594b3"
      },
      "id": "stJrWprLQxIN",
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'SPIN mostly operates within the strategic area IoT@NTNU and is located at the main campus Gløshaugen in Trondheim, Norway.\\nResearch Team\\nSalvo Rossi, Pierluigi\\n\\r\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\tProfessor, Deputy Head of Department \\nBackground:'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(vectordb._collection.count())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VPn8cewkQ0VW",
        "outputId": "ada81fb5-3e17-49ed-91a4-59256a449632"
      },
      "id": "VPn8cewkQ0VW",
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Try with MMR\n",
        "docs_mmr = vectordb.max_marginal_relevance_search(question,k=3)\n",
        "docs_mmr[1].page_content[:100]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "jNB3_1UfUk7u",
        "outputId": "aa706b64-d106-451e-b05d-24aaead3f769"
      },
      "id": "jNB3_1UfUk7u",
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Background: \\r\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\tPh.D. Computer Engineering (University of Naples \"Federico II\", Italy)\\r\\n\\t\\t\\t\\t'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.retrievers import ContextualCompressionRetriever\n",
        "from langchain.retrievers.document_compressors import LLMChainExtractor"
      ],
      "metadata": {
        "id": "76RooWPhtYx4"
      },
      "id": "76RooWPhtYx4",
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.llms import OpenAI\n",
        "\n",
        "# Wrap our vectorstore\n",
        "llm = OpenAI(temperature=0, model=\"gpt-3.5-turbo-instruct\")\n",
        "compressor = LLMChainExtractor.from_llm(llm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O8D85TJbuTXC",
        "outputId": "7e8ec139-1a8b-48ed-b923-23b22e47a070"
      },
      "id": "O8D85TJbuTXC",
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-105-65cc44205828>:4: LangChainDeprecationWarning: The class `OpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import OpenAI``.\n",
            "  llm = OpenAI(temperature=0, model=\"gpt-3.5-turbo-instruct\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "compression_retriever = ContextualCompressionRetriever(\n",
        "    base_compressor=compressor,\n",
        "    base_retriever=vectordb.as_retriever()\n",
        ")\n",
        "def pretty_print_docs(docs):\n",
        "    print(f\"\\n{'-' * 100}\\n\".join([f\"Document {i+1}:\\n\\n\" + d.page_content for i, d in enumerate(docs)]))\n"
      ],
      "metadata": {
        "id": "6j8oWiWEuhoQ"
      },
      "id": "6j8oWiWEuhoQ",
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"What is Spin?\"\n",
        "compressed_docs = compression_retriever.get_relevant_documents(question)\n",
        "pretty_print_docs(compressed_docs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CdYoqt72ulIR",
        "outputId": "b7ff3118-f305-43de-8336-f18a50dbdbfd"
      },
      "id": "CdYoqt72ulIR",
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Document 1:\n",
            "\n",
            "SPIN is part of the Signal Processing Group at the Department of Electronic Systems, Faculty of Information Technology and Electrical Engineering, Norwegian University of Science and Technology.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Document 2:\n",
            "\n",
            "The research group SPIN (Signal Processing for Industry N.0) focuses on research in statistical signal processing and machine learning applied to sensors data and related to the digitalization of the industrial sector, primarily within construction, energy, and ocean.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Document 3:\n",
            "\n",
            "SPIN mostly operates within the strategic area IoT@NTNU and is located at the main campus Gløshaugen in Trondheim, Norway.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import datetime\n",
        "current_date = datetime.datetime.now().date()\n",
        "if current_date < datetime.date(2023, 9, 2):\n",
        "    llm_name = \"gpt-4\"\n",
        "else:\n",
        "    llm_name = \"gpt-4\"\n",
        "print(llm_name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nYwTjYjQu6-X",
        "outputId": "660eb7e3-0c5f-4ab9-95f5-6318fb3a6097"
      },
      "id": "nYwTjYjQu6-X",
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "gpt-4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain.prompts import PromptTemplate\n",
        "llm = ChatOpenAI(model_name=llm_name, temperature=0)\n",
        "# Build prompt\n",
        "template = \"\"\"Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer. Use three sentences maximum. Keep the answer as concise as possible. Always say \"thanks for asking!\" at the end of the answer.\n",
        "{context}\n",
        "Question: {question}\n",
        "Helpful Answer:\"\"\"\n",
        "QA_CHAIN_PROMPT = PromptTemplate.from_template(template)\n",
        "qa_chain = RetrievalQA.from_chain_type(\n",
        "    llm,\n",
        "    retriever=vectordb.as_retriever()\n",
        ")\n"
      ],
      "metadata": {
        "id": "Zf-0N0uCwNhc"
      },
      "id": "Zf-0N0uCwNhc",
      "execution_count": 130,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"Who is working on Graph SIgnal Processing in the Group\"\n",
        "result = qa_chain({\"query\": question})\n",
        "result"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wn11fNUBwTeJ",
        "outputId": "e6c8b534-3f7a-47f5-dab8-d842ec98baea"
      },
      "id": "Wn11fNUBwTeJ",
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'query': 'Who is working on Graph SIgnal Processing in the Group',\n",
              " 'result': 'Muhammad Asaad Cheema, a PhD student, is working on \"Graph Signal Processing for Irregular Time Series\" in the SPIN research group.'}"
            ]
          },
          "metadata": {},
          "execution_count": 135
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.19"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}